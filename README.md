# How to unify Keras NLP and Hugging Face

From the official [announcement](https://huggingface.co/blog/keras-nlp-integration):

> We're thrilled to announce a significant step forward for the NLP
community: Transformers and KerasNLP now have a shared model save format.
This means that models of the transformers library on the Hugging Face Hub
can now also be loaded directly into KerasNLP - immediately making a huge
range of fine-tuned models available to KerasNLP users. Initially, this
integration focuses on enabling the use of Gemma (1 and 2), Llama 3, and PaliGemma
models, with plans to expand compatibility to a wider range of architectures in
the near future.

I have created this repository for anyone to be able to quickly contribute to Keras NLP
using the integration. You would need to follow the two notebook in order to understand
what happens under the hood of the integration.
