{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPQsV26gUca+HsnZ+93R+Jz"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4fcf4d77e66e4d42b309dbac31971cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_771871c62b914f2b93d008448df3b84b",
              "IPY_MODEL_c32289a3769d41b78bea37887fe87780",
              "IPY_MODEL_c2cc284d376148348bfc006e87a43142"
            ],
            "layout": "IPY_MODEL_ee23d9dfceaa40d99506aa1aa6c65fad"
          }
        },
        "771871c62b914f2b93d008448df3b84b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2650a3a16304497ab6d92bcb96907d7d",
            "placeholder": "​",
            "style": "IPY_MODEL_9bc30303d1e740c1a73cf17d9157b421",
            "value": "config.json: 100%"
          }
        },
        "c32289a3769d41b78bea37887fe87780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6865506fa5954811810b294b1863705f",
            "max": 1027,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_722dfa585ce04ddebc3a46b72599cd62",
            "value": 1027
          }
        },
        "c2cc284d376148348bfc006e87a43142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_667aa2b6511742c281efbb6d62b0fea5",
            "placeholder": "​",
            "style": "IPY_MODEL_2eb666e424cd410187386c86bfd99b9e",
            "value": " 1.03k/1.03k [00:00&lt;00:00, 92.0kB/s]"
          }
        },
        "ee23d9dfceaa40d99506aa1aa6c65fad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2650a3a16304497ab6d92bcb96907d7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bc30303d1e740c1a73cf17d9157b421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6865506fa5954811810b294b1863705f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "722dfa585ce04ddebc3a46b72599cd62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "667aa2b6511742c281efbb6d62b0fea5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eb666e424cd410187386c86bfd99b9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cd5045891a841ec9335e06e0453dd8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b376d67872824af1a6cc405a76646fc7",
              "IPY_MODEL_b95909b9cdce4e9586f3a78b24dff2cf",
              "IPY_MODEL_743315b142a24cabb82c30b0af1576a9"
            ],
            "layout": "IPY_MODEL_af8c6449ee244ba991d9839ab87898a5"
          }
        },
        "b376d67872824af1a6cc405a76646fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe6c0d830cd24b4fbcb62978919169b3",
            "placeholder": "​",
            "style": "IPY_MODEL_71a176d0ced94c4cbaa405b9b13d3171",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "b95909b9cdce4e9586f3a78b24dff2cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd65cd14e77e43f2a2ceff653d1c107b",
            "max": 62552,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33ed0e3e2d6e4e81853862d16caa9b7f",
            "value": 62552
          }
        },
        "743315b142a24cabb82c30b0af1576a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cef531eccca4cec8d954a82f6fa71da",
            "placeholder": "​",
            "style": "IPY_MODEL_bcd5f1ba61074593aab4d7b120cdaaa7",
            "value": " 62.6k/62.6k [00:00&lt;00:00, 317kB/s]"
          }
        },
        "af8c6449ee244ba991d9839ab87898a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe6c0d830cd24b4fbcb62978919169b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71a176d0ced94c4cbaa405b9b13d3171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd65cd14e77e43f2a2ceff653d1c107b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33ed0e3e2d6e4e81853862d16caa9b7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8cef531eccca4cec8d954a82f6fa71da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcd5f1ba61074593aab4d7b120cdaaa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "070a1d2344fd4be7ac68f1b42de2529c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be1fe9f7e5fc46938d25eb602dd120b2",
              "IPY_MODEL_aa145bb5df7443fb9802aa95c564f266",
              "IPY_MODEL_1ef095c9d4b041a5a63c7c4a7cb916ef"
            ],
            "layout": "IPY_MODEL_4ba9769fad3c4501a0fa6b5165dbfe19"
          }
        },
        "be1fe9f7e5fc46938d25eb602dd120b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d95bede67104c2b89ad2072eb5625ca",
            "placeholder": "​",
            "style": "IPY_MODEL_b8a8d0fdda05469a8842ffffa66ab491",
            "value": "model-00001-of-00003.safetensors: 100%"
          }
        },
        "aa145bb5df7443fb9802aa95c564f266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d93b87aa270849e983636de39bd15261",
            "max": 4953412480,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4818fb4531bc462c898879c2f866ae81",
            "value": 4953412480
          }
        },
        "1ef095c9d4b041a5a63c7c4a7cb916ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe15d97568a44d3ebe832a96a9fdf279",
            "placeholder": "​",
            "style": "IPY_MODEL_abcef98c1e7c49468c5e79d5ed3efac8",
            "value": " 4.95G/4.95G [03:08&lt;00:00, 25.4MB/s]"
          }
        },
        "4ba9769fad3c4501a0fa6b5165dbfe19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d95bede67104c2b89ad2072eb5625ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8a8d0fdda05469a8842ffffa66ab491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d93b87aa270849e983636de39bd15261": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4818fb4531bc462c898879c2f866ae81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe15d97568a44d3ebe832a96a9fdf279": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abcef98c1e7c49468c5e79d5ed3efac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f79dfa604f244cf78b2cc93f7d806756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63c7bbb3477d4c1d82d2c38c665fba6c",
              "IPY_MODEL_98a5794590c14eb0a89fc5b51ecf2e1a",
              "IPY_MODEL_106f7c022ad442a387f778f838bd02c3"
            ],
            "layout": "IPY_MODEL_c8581f71f182405e911f8085314e4bb7"
          }
        },
        "63c7bbb3477d4c1d82d2c38c665fba6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_156626652f8c4646b59d720e69357e0d",
            "placeholder": "​",
            "style": "IPY_MODEL_42229a90a8f04cc98230b0a23885656b",
            "value": "model-00003-of-00003.safetensors: 100%"
          }
        },
        "98a5794590c14eb0a89fc5b51ecf2e1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3b361e7e76647f39f23a1b5d7635fc7",
            "max": 1740714288,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8def044e75564006a8397cdc250a30be",
            "value": 1740714288
          }
        },
        "106f7c022ad442a387f778f838bd02c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_678d5678b648463d8fbc07521fb3dccb",
            "placeholder": "​",
            "style": "IPY_MODEL_5675c3d5245d4d2296cb91a7e6e5636a",
            "value": " 1.74G/1.74G [01:07&lt;00:00, 26.5MB/s]"
          }
        },
        "c8581f71f182405e911f8085314e4bb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "156626652f8c4646b59d720e69357e0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42229a90a8f04cc98230b0a23885656b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3b361e7e76647f39f23a1b5d7635fc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8def044e75564006a8397cdc250a30be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "678d5678b648463d8fbc07521fb3dccb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5675c3d5245d4d2296cb91a7e6e5636a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbfd88f35bc64c8aa2f08462b27cb2d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65af41379e2342f69d6aee825e181bca",
              "IPY_MODEL_8b8c8af64e404e90b775303ea65f4f3c",
              "IPY_MODEL_cee4c1dd27fa4d34987195be9323e0f1"
            ],
            "layout": "IPY_MODEL_2763ec7d43e34d57853eab3687750c26"
          }
        },
        "65af41379e2342f69d6aee825e181bca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2349e44b804f475386fcaeb8b3118005",
            "placeholder": "​",
            "style": "IPY_MODEL_38fa29b225a9496aa84ee4d38425648b",
            "value": "model-00002-of-00003.safetensors: 100%"
          }
        },
        "8b8c8af64e404e90b775303ea65f4f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c12f8e6e3efb45ff935f56ee6f8616c9",
            "max": 4999820608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59088672bca44768bc0ac538c4af3512",
            "value": 4999820608
          }
        },
        "cee4c1dd27fa4d34987195be9323e0f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3eb7a8f75c9b46a59650226272ba350b",
            "placeholder": "​",
            "style": "IPY_MODEL_8f1356d452aa4287a38a0e7dbfb3502b",
            "value": " 5.00G/5.00G [03:13&lt;00:00, 26.2MB/s]"
          }
        },
        "2763ec7d43e34d57853eab3687750c26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2349e44b804f475386fcaeb8b3118005": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38fa29b225a9496aa84ee4d38425648b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c12f8e6e3efb45ff935f56ee6f8616c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59088672bca44768bc0ac538c4af3512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3eb7a8f75c9b46a59650226272ba350b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f1356d452aa4287a38a0e7dbfb3502b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "In the previous notebook we very able to successfully build a Keras NLP Backbone model using the Hugging Face configuration.\n",
        "\n",
        "The next step would be to assign pre-trained weights into the randomly initialized Backbone model. Before assigning the weights, I like to double check them.\n",
        "\n",
        "In this notebook we build the KerasNLP Backbone from Kaggle's preset (with trained weights) and compare the weights of the model with the `safetensor` checkpoint of Hugging Face."
      ],
      "metadata": {
        "id": "LSUrTr6pmQ7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup and Imports"
      ],
      "metadata": {
        "id": "sOSPrkOBnDdk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MJAH4OX3_Yl",
        "outputId": "73a33b04-5bef-4637-e356-2ca9f8d0bb37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Invalid requirement: '_U'\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.8/571.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m125.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.7/347.7 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q _U safetensors\n",
        "!pip install -q -U keras-nlp\n",
        "!pip install -q -U keras>=3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get(\"KAGGLE_USERNAME\")\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get(\"KAGGLE_KEY\")"
      ],
      "metadata": {
        "id": "EZEZQOgj-Csy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "keras.config.set_dtype_policy(\"bfloat16\")\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "\n",
        "from safetensors import safe_open\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "from keras_nlp.models import (\n",
        "    PaliGemmaBackbone,\n",
        ")"
      ],
      "metadata": {
        "id": "aaWOp_mM-Eza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Safetensor Files from HF Hub"
      ],
      "metadata": {
        "id": "I7jzaUo8-ycP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hf_model_id = \"google/paligemma-3b-pt-224\"\n",
        "\n",
        "transformers_config = hf_hub_download(\n",
        "    repo_id=hf_model_id,\n",
        "    filename=\"config.json\"\n",
        ")\n",
        "safetensor_config = hf_hub_download(\n",
        "    repo_id=hf_model_id,\n",
        "    filename=\"model.safetensors.index.json\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "4fcf4d77e66e4d42b309dbac31971cfe",
            "771871c62b914f2b93d008448df3b84b",
            "c32289a3769d41b78bea37887fe87780",
            "c2cc284d376148348bfc006e87a43142",
            "ee23d9dfceaa40d99506aa1aa6c65fad",
            "2650a3a16304497ab6d92bcb96907d7d",
            "9bc30303d1e740c1a73cf17d9157b421",
            "6865506fa5954811810b294b1863705f",
            "722dfa585ce04ddebc3a46b72599cd62",
            "667aa2b6511742c281efbb6d62b0fea5",
            "2eb666e424cd410187386c86bfd99b9e",
            "8cd5045891a841ec9335e06e0453dd8c",
            "b376d67872824af1a6cc405a76646fc7",
            "b95909b9cdce4e9586f3a78b24dff2cf",
            "743315b142a24cabb82c30b0af1576a9",
            "af8c6449ee244ba991d9839ab87898a5",
            "fe6c0d830cd24b4fbcb62978919169b3",
            "71a176d0ced94c4cbaa405b9b13d3171",
            "dd65cd14e77e43f2a2ceff653d1c107b",
            "33ed0e3e2d6e4e81853862d16caa9b7f",
            "8cef531eccca4cec8d954a82f6fa71da",
            "bcd5f1ba61074593aab4d7b120cdaaa7"
          ]
        },
        "id": "nrVdK5jv-M5R",
        "outputId": "5a639b86-779b-4b15-dada-c275988f9a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.03k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4fcf4d77e66e4d42b309dbac31971cfe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/62.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8cd5045891a841ec9335e06e0453dd8c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(transformers_config, \"r\") as f:\n",
        "    transformers_config = json.load(f)\n",
        "\n",
        "with open(safetensor_config, \"r\") as f:\n",
        "    safetensor_config = json.load(f)"
      ],
      "metadata": {
        "id": "rQqWh4rJ-VJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we map safe tensor file names with the safe\n",
        "# path to which they are downloaded\n",
        "safetensor_files = {\n",
        "    fname:hf_hub_download(repo_id=hf_model_id, filename=fname) for fname in set(safetensor_config['weight_map'].values())\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "070a1d2344fd4be7ac68f1b42de2529c",
            "be1fe9f7e5fc46938d25eb602dd120b2",
            "aa145bb5df7443fb9802aa95c564f266",
            "1ef095c9d4b041a5a63c7c4a7cb916ef",
            "4ba9769fad3c4501a0fa6b5165dbfe19",
            "6d95bede67104c2b89ad2072eb5625ca",
            "b8a8d0fdda05469a8842ffffa66ab491",
            "d93b87aa270849e983636de39bd15261",
            "4818fb4531bc462c898879c2f866ae81",
            "fe15d97568a44d3ebe832a96a9fdf279",
            "abcef98c1e7c49468c5e79d5ed3efac8",
            "f79dfa604f244cf78b2cc93f7d806756",
            "63c7bbb3477d4c1d82d2c38c665fba6c",
            "98a5794590c14eb0a89fc5b51ecf2e1a",
            "106f7c022ad442a387f778f838bd02c3",
            "c8581f71f182405e911f8085314e4bb7",
            "156626652f8c4646b59d720e69357e0d",
            "42229a90a8f04cc98230b0a23885656b",
            "f3b361e7e76647f39f23a1b5d7635fc7",
            "8def044e75564006a8397cdc250a30be",
            "678d5678b648463d8fbc07521fb3dccb",
            "5675c3d5245d4d2296cb91a7e6e5636a",
            "fbfd88f35bc64c8aa2f08462b27cb2d0",
            "65af41379e2342f69d6aee825e181bca",
            "8b8c8af64e404e90b775303ea65f4f3c",
            "cee4c1dd27fa4d34987195be9323e0f1",
            "2763ec7d43e34d57853eab3687750c26",
            "2349e44b804f475386fcaeb8b3118005",
            "38fa29b225a9496aa84ee4d38425648b",
            "c12f8e6e3efb45ff935f56ee6f8616c9",
            "59088672bca44768bc0ac538c4af3512",
            "3eb7a8f75c9b46a59650226272ba350b",
            "8f1356d452aa4287a38a0e7dbfb3502b"
          ]
        },
        "id": "896gOZL9_X7Y",
        "outputId": "43f8769b-a508-4223-e0ad-1c2e96f8c033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "070a1d2344fd4be7ac68f1b42de2529c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f79dfa604f244cf78b2cc93f7d806756"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbfd88f35bc64c8aa2f08462b27cb2d0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the Keras NLP backbone"
      ],
      "metadata": {
        "id": "AC6mFz77_Fzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_model_id = \"pali_gemma_3b_224\"\n",
        "keras_backbone = PaliGemmaBackbone.from_preset(\n",
        "    kaggle_model_id,\n",
        "    load_weights=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGO_fPc-_Fc0",
        "outputId": "6c908fd5-bd06-4422-9b11-4b92d1275b9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/paligemma/keras/pali_gemma_3b_224/1/download/model.safetensors...\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/paligemma/keras/pali_gemma_3b_224/1/download/model.safetensors.index.json...\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/paligemma/keras/pali_gemma_3b_224/1/download/metadata.json...\n",
            "100%|██████████| 143/143 [00:00<00:00, 172kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/paligemma/keras/pali_gemma_3b_224/1/download/config.json...\n",
            "100%|██████████| 861/861 [00:00<00:00, 1.25MB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/paligemma/keras/pali_gemma_3b_224/1/download/model.weights.h5...\n",
            "100%|██████████| 5.45G/5.45G [04:55<00:00, 19.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check Keras and HF weights\n",
        "\n",
        "The `check_keras_weight` function directly comes from [`set_keras_weight`](https://github.com/keras-team/keras-nlp/blob/be524fc3c2fe955b7977bcc49a72036eb7d92cae/keras_nlp/src/utils/transformers/safetensor_utils.py#L20) in the Keras NLP repository."
      ],
      "metadata": {
        "id": "NjtCr3B9_k48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_keras_weight(\n",
        "    safetensor_files,\n",
        "    safetensor_config,\n",
        "    keras_variable,\n",
        "    hf_weight_key,\n",
        "    hook_fn=None,\n",
        "):\n",
        "    safetensor_file = safetensor_files[\n",
        "        safetensor_config[\"weight_map\"][hf_weight_key]\n",
        "    ]\n",
        "    with safe_open(safetensor_file, framework=\"np\") as f:\n",
        "        hf_tensor = f.get_tensor(hf_weight_key)\n",
        "\n",
        "        print(hf_weight_key)\n",
        "        print(f\"{hf_tensor.shape=}\")\n",
        "        print(f\"{keras_variable.shape=}\")\n",
        "\n",
        "        if hook_fn:\n",
        "            hf_tensor = hook_fn(hf_tensor, list(keras_variable.shape))\n",
        "\n",
        "        np.testing.assert_allclose(\n",
        "            keras_variable,\n",
        "            hf_tensor,\n",
        "            atol=1e-02,\n",
        "            rtol=1e-02,\n",
        "        )\n",
        "\n",
        "port_weight = partial(\n",
        "    check_keras_weight,\n",
        "    safetensor_files=safetensor_files,\n",
        "    safetensor_config=safetensor_config,\n",
        ")"
      ],
      "metadata": {
        "id": "g8UX2urQ_moM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Tower"
      ],
      "metadata": {
        "id": "exZIsw3OdYeO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding"
      ],
      "metadata": {
        "id": "F2owsLRXkiej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "port_weight(\n",
        "    keras_variable=keras_backbone.vit_encoder.get_layer(\"image_encoder\").vision_embeddings.patch_embedding.bias,\n",
        "    hf_weight_key=\"vision_tower.vision_model.embeddings.patch_embedding.bias\",\n",
        ")\n",
        "\n",
        "port_weight(\n",
        "    keras_variable=keras_backbone.vit_encoder.get_layer(\"image_encoder\").vision_embeddings.patch_embedding.kernel,\n",
        "    hf_weight_key=\"vision_tower.vision_model.embeddings.patch_embedding.weight\",\n",
        "    hook_fn=lambda hf_tensor, keras_shape: np.transpose(\n",
        "        hf_tensor,\n",
        "        axes=(2, 3, 1, 0),\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEkI5bFlhsC2",
        "outputId": "4ee65b77-c720-48ec-d889-89c4b54ec775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vision_tower.vision_model.embeddings.patch_embedding.weight\n",
            "hf_tensor.shape=(1152, 3, 14, 14)\n",
            "keras_variable.shape=TensorShape([14, 14, 3, 1152])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "port_weight(\n",
        "    keras_variable=keras_backbone.vit_encoder.get_layer(\"image_encoder\").vision_embeddings.position_embedding.embeddings,\n",
        "    hf_weight_key=\"vision_tower.vision_model.embeddings.position_embedding.weight\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYwBl39Mj9_K",
        "outputId": "cdbca47d-72ee-4f92-aefe-d0b0b4629d44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vision_tower.vision_model.embeddings.position_embedding.weight\n",
            "hf_tensor.shape=(256, 1152)\n",
            "keras_variable.shape=TensorShape([256, 1152])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Norms"
      ],
      "metadata": {
        "id": "liaSkySOkl_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "port_weight(\n",
        "    keras_variable=keras_backbone.vit_encoder.get_layer(\"image_encoder\").encoder_layer_norm.gamma,\n",
        "    hf_weight_key=\"vision_tower.vision_model.post_layernorm.weight\",\n",
        ")\n",
        "\n",
        "port_weight(\n",
        "    keras_variable=keras_backbone.vit_encoder.get_layer(\"image_encoder\").encoder_layer_norm.beta,\n",
        "    hf_weight_key=\"vision_tower.vision_model.post_layernorm.bias\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E42zgToMk-Jp",
        "outputId": "3713b8e9-3c07-4d2f-d861-fed1d39acbda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vision_tower.vision_model.post_layernorm.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.post_layernorm.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "YiXtfd7LkV7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for index in range(keras_backbone.vit_encoder.get_layer(\"image_encoder\").num_layers):\n",
        "\n",
        "    port_weight(\n",
        "        keras_variable=keras_backbone.vit_encoder.get_layer(\"image_encoder\").resblocks[index].layer_norm_1.beta,\n",
        "        hf_weight_key=f\"vision_tower.vision_model.encoder.layers.{index}.layer_norm1.bias\",\n",
        "    )\n",
        "\n",
        "    port_weight(\n",
        "        keras_variable=keras_backbone.vit_encoder.get_layer(\"image_encoder\").resblocks[index].layer_norm_1.gamma,\n",
        "        hf_weight_key=f\"vision_tower.vision_model.encoder.layers.{index}.layer_norm1.weight\",\n",
        "    )\n",
        "\n",
        "    port_weight(\n",
        "        keras_variable=keras_backbone.vit_encoder.get_layer(\"image_encoder\").resblocks[index].layer_norm_2.beta,\n",
        "        hf_weight_key=f\"vision_tower.vision_model.encoder.layers.{index}.layer_norm2.bias\",\n",
        "    )\n",
        "\n",
        "    port_weight(\n",
        "        keras_variable=keras_backbone.vit_encoder.get_layer(\"image_encoder\").resblocks[index].layer_norm_2.gamma,\n",
        "        hf_weight_key=f\"vision_tower.vision_model.encoder.layers.{index}.layer_norm2.weight\",\n",
        "    )\n",
        "\n",
        "    port_weight(\n",
        "        keras_variable=keras_backbone.vit_encoder.get_layer(\"image_encoder\").resblocks[index].mlp_dense_1.kernel,\n",
        "        hf_weight_key=f\"vision_tower.vision_model.encoder.layers.{index}.mlp.fc1.weight\",\n",
        "        hook_fn=lambda hf_tensor, keras_shape: np.transpose(\n",
        "            hf_tensor,\n",
        "            axes=(1, 0),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    port_weight(\n",
        "        keras_variable=keras_backbone.vit_encoder.get_layer(\"image_encoder\").resblocks[index].mlp_dense_1.bias,\n",
        "        hf_weight_key=f\"vision_tower.vision_model.encoder.layers.{index}.mlp.fc1.bias\",\n",
        "    )\n",
        "\n",
        "    port_weight(\n",
        "        keras_variable=keras_backbone.vit_encoder.get_layer(\"image_encoder\").resblocks[index].mlp_dense_2.kernel,\n",
        "        hf_weight_key=f\"vision_tower.vision_model.encoder.layers.{index}.mlp.fc2.weight\",\n",
        "        hook_fn=lambda hf_tensor, keras_shape: np.transpose(\n",
        "            hf_tensor,\n",
        "            axes=(1, 0),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    port_weight(\n",
        "        keras_variable=keras_backbone.vit_encoder.get_layer(\"image_encoder\").resblocks[index].mlp_dense_2.bias,\n",
        "        hf_weight_key=f\"vision_tower.vision_model.encoder.layers.{index}.mlp.fc2.bias\",\n",
        "    )\n",
        "\n",
        "    port_weight(\n",
        "        keras_variable=keras_backbone.vit_encoder.get_layer(\"image_encoder\").resblocks[index].attn.key_proj.bias,\n",
        "        hf_weight_key=f\"vision_tower.vision_model.encoder.layers.{index}.self_attn.k_proj.bias\",\n",
        "    )\n",
        "\n",
        "    port_weight(\n",
        "        keras_variable=keras_backbone.vit_encoder.get_layer(\"image_encoder\").resblocks[index].attn.key_proj.kernel,\n",
        "        hf_weight_key=f\"vision_tower.vision_model.encoder.layers.{index}.self_attn.k_proj.weight\",\n",
        "        hook_fn=lambda hf_tensor, keras_shape: np.transpose(\n",
        "            hf_tensor,\n",
        "            axes=(1, 0),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    port_weight(\n",
        "        keras_variable=keras_backbone.vit_encoder.get_layer(\"image_encoder\").resblocks[index].attn.out_proj.bias,\n",
        "        hf_weight_key=f\"vision_tower.vision_model.encoder.layers.{index}.self_attn.out_proj.bias\",\n",
        "    )\n",
        "\n",
        "    port_weight(\n",
        "        keras_variable=keras_backbone.vit_encoder.get_layer(\"image_encoder\").resblocks[index].attn.out_proj.kernel,\n",
        "        hf_weight_key=f\"vision_tower.vision_model.encoder.layers.{index}.self_attn.out_proj.weight\",\n",
        "        hook_fn=lambda hf_tensor, keras_shape: np.transpose(\n",
        "            hf_tensor,\n",
        "            axes=(1, 0),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    port_weight(\n",
        "        keras_variable=keras_backbone.vit_encoder.get_layer(\"image_encoder\").resblocks[index].attn.query_proj.bias,\n",
        "        hf_weight_key=f\"vision_tower.vision_model.encoder.layers.{index}.self_attn.q_proj.bias\",\n",
        "    )\n",
        "\n",
        "    port_weight(\n",
        "        keras_variable=keras_backbone.vit_encoder.get_layer(\"image_encoder\").resblocks[index].attn.query_proj.kernel,\n",
        "        hf_weight_key=f\"vision_tower.vision_model.encoder.layers.{index}.self_attn.q_proj.weight\",\n",
        "        hook_fn=lambda hf_tensor, keras_shape: np.transpose(\n",
        "            hf_tensor,\n",
        "            axes=(1, 0),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    port_weight(\n",
        "        keras_variable=keras_backbone.vit_encoder.get_layer(\"image_encoder\").resblocks[index].attn.value_proj.bias,\n",
        "        hf_weight_key=f\"vision_tower.vision_model.encoder.layers.{index}.self_attn.v_proj.bias\",\n",
        "    )\n",
        "\n",
        "    port_weight(\n",
        "        keras_variable=keras_backbone.vit_encoder.get_layer(\"image_encoder\").resblocks[index].attn.value_proj.kernel,\n",
        "        hf_weight_key=f\"vision_tower.vision_model.encoder.layers.{index}.self_attn.v_proj.weight\",\n",
        "        hook_fn=lambda hf_tensor, keras_shape: np.transpose(\n",
        "            hf_tensor,\n",
        "            axes=(1, 0),\n",
        "        ),\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fShLxVfmN4D",
        "outputId": "f8138d08-6daa-40ab-d0bd-faae0d3cda72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vision_tower.vision_model.encoder.layers.0.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.0.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.0.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.0.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.1.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.1.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.1.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.1.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.2.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.2.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.2.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.2.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.3.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.3.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.3.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.3.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.4.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.4.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.4.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.4.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.5.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.5.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.5.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.5.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.6.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.6.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.6.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.6.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.7.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.7.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.7.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.7.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.8.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.8.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.8.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.8.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.9.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.9.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.9.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.9.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.10.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.10.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.10.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.10.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.11.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.11.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.11.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.11.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.12.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.12.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.12.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.12.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.13.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.13.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.13.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.13.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.14.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.14.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.14.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.14.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.15.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.15.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.15.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.15.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.16.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.16.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.16.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.16.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.17.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.17.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.17.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.17.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.18.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.18.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.18.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.18.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.19.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.19.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.19.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.19.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.20.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.20.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.20.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.20.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.21.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.21.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.21.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.21.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.22.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.22.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.22.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.22.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.23.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.23.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.23.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.23.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.24.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.24.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.24.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.24.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.24.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.24.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.24.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.24.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.25.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.25.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.25.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.25.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.25.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.25.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.25.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.25.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.26.layer_norm1.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.26.layer_norm1.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.26.layer_norm2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.26.layer_norm2.weight\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.26.mlp.fc1.weight\n",
            "hf_tensor.shape=(4304, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 4304])\n",
            "vision_tower.vision_model.encoder.layers.26.mlp.fc1.bias\n",
            "hf_tensor.shape=(4304,)\n",
            "keras_variable.shape=TensorShape([4304])\n",
            "vision_tower.vision_model.encoder.layers.26.mlp.fc2.weight\n",
            "hf_tensor.shape=(1152, 4304)\n",
            "keras_variable.shape=TensorShape([4304, 1152])\n",
            "vision_tower.vision_model.encoder.layers.26.mlp.fc2.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.26.self_attn.k_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.26.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.26.self_attn.out_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.26.self_attn.out_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.26.self_attn.q_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.26.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n",
            "vision_tower.vision_model.encoder.layers.26.self_attn.v_proj.bias\n",
            "hf_tensor.shape=(1152,)\n",
            "keras_variable.shape=TensorShape([1152])\n",
            "vision_tower.vision_model.encoder.layers.26.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(1152, 1152)\n",
            "keras_variable.shape=TensorShape([1152, 1152])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multimodal Projection"
      ],
      "metadata": {
        "id": "alTGYdTh7s3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "port_weight(\n",
        "    keras_variable=keras_backbone.vit_encoder.get_layer(\"image_classifier\").kernel,\n",
        "    hf_weight_key=\"multi_modal_projector.linear.weight\",\n",
        "    hook_fn=lambda hf_tensor, keras_shape: np.transpose(\n",
        "        hf_tensor,\n",
        "        axes=(1, 0),\n",
        "    ),\n",
        ")\n",
        "\n",
        "port_weight(\n",
        "    keras_variable=keras_backbone.vit_encoder.get_layer(\"image_classifier\").bias,\n",
        "    hf_weight_key=\"multi_modal_projector.linear.bias\",\n",
        ")"
      ],
      "metadata": {
        "id": "uyTnqAPN7sgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Language Tower"
      ],
      "metadata": {
        "id": "bl3AuZDDqJ6L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding"
      ],
      "metadata": {
        "id": "ENlzWszPAIri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = 0"
      ],
      "metadata": {
        "id": "zZ6j8BV9rHvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index in range(keras_backbone.num_layers):\n",
        "    decoder_layer = keras_backbone.transformer_layers[index]\n",
        "\n",
        "    # Norm layers\n",
        "    port_weight(\n",
        "        keras_variable=decoder_layer.pre_attention_norm.scale,\n",
        "        hf_weight_key=f\"language_model.model.layers.{index}.input_layernorm.weight\",\n",
        "    )\n",
        "    port_weight(\n",
        "        keras_variable=decoder_layer.pre_ffw_norm.scale,\n",
        "        hf_weight_key=f\"language_model.model.layers.{index}.post_attention_layernorm.weight\",\n",
        "    )\n",
        "\n",
        "    # Attention layers\n",
        "    port_weight(\n",
        "        keras_variable=decoder_layer.attention.query_dense.kernel,\n",
        "        hf_weight_key=f\"language_model.model.layers.{index}.self_attn.q_proj.weight\",\n",
        "        # rearrange_patterns=\"(a c) b -> a b c\",\n",
        "        # rearrange_dims={\"a\": backbone.num_query_heads},\n",
        "        hook_fn=lambda hf_tensor, keras_shape: np.transpose(\n",
        "            np.reshape(\n",
        "                hf_tensor,\n",
        "                (keras_shape[0], keras_shape[2], keras_shape[1]),\n",
        "            ),\n",
        "            axes=(0, 2, 1),\n",
        "        ),\n",
        "    )\n",
        "    port_weight(\n",
        "        keras_variable=decoder_layer.attention.key_dense.kernel,\n",
        "        hf_weight_key=f\"language_model.model.layers.{index}.self_attn.k_proj.weight\",\n",
        "        # rearrange_patterns=\"(a c) b -> a b c\",\n",
        "        # rearrange_dims={\"a\": backbone.num_key_value_heads},\n",
        "        hook_fn=lambda hf_tensor, keras_shape: np.transpose(\n",
        "            np.reshape(\n",
        "                hf_tensor,\n",
        "                (keras_shape[0], keras_shape[2], keras_shape[1]),\n",
        "            ),\n",
        "            axes=(0, 2, 1),\n",
        "        ),\n",
        "    )\n",
        "    port_weight(\n",
        "        keras_variable=decoder_layer.attention.value_dense.kernel,\n",
        "        hf_weight_key=f\"language_model.model.layers.{index}.self_attn.v_proj.weight\",\n",
        "        # rearrange_patterns=\"(a c) b -> a b c\",\n",
        "        # rearrange_dims={\"a\": backbone.num_key_value_heads},\n",
        "        hook_fn=lambda hf_tensor, keras_shape: np.transpose(\n",
        "            np.reshape(\n",
        "                hf_tensor,\n",
        "                (keras_shape[0], keras_shape[2], keras_shape[1]),\n",
        "            ),\n",
        "            axes=(0, 2, 1),\n",
        "        ),\n",
        "    )\n",
        "    port_weight(\n",
        "        keras_variable=decoder_layer.attention.output_dense.kernel,\n",
        "        hf_weight_key=f\"language_model.model.layers.{index}.self_attn.o_proj.weight\",\n",
        "        # rearrange_patterns=\"c (a b) -> a b c\",\n",
        "        # rearrange_dims={\"a\": backbone.num_query_heads},\n",
        "        hook_fn=lambda hf_tensor, keras_shape: np.transpose(\n",
        "            np.reshape(\n",
        "                hf_tensor,\n",
        "                (keras_shape[2], keras_shape[0], keras_shape[1]),\n",
        "            ),\n",
        "            axes=(1, 2, 0),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    # MLP layers\n",
        "    port_weight(\n",
        "        keras_variable=decoder_layer.gating_ffw.variables[0],\n",
        "        hf_weight_key=f\"language_model.model.layers.{index}.mlp.gate_proj.weight\",\n",
        "        # rearrange_patterns=\"b a -> a b\",\n",
        "        hook_fn=lambda hf_tensor, _: np.transpose(hf_tensor, axes=(1, 0)),\n",
        "    )\n",
        "    port_weight(\n",
        "        keras_variable=decoder_layer.gating_ffw_2.variables[0],\n",
        "        hf_weight_key=f\"language_model.model.layers.{index}.mlp.up_proj.weight\",\n",
        "        # rearrange_patterns=\"b a -> a b\",\n",
        "        hook_fn=lambda hf_tensor, _: np.transpose(hf_tensor, axes=(1, 0)),\n",
        "    )\n",
        "    port_weight(\n",
        "        keras_variable=decoder_layer.ffw_linear.variables[0],\n",
        "        hf_weight_key=f\"language_model.model.layers.{index}.mlp.down_proj.weight\",\n",
        "        # rearrange_patterns=\"b a -> a b\",\n",
        "        hook_fn=lambda hf_tensor, _: np.transpose(hf_tensor, axes=(1, 0)),\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-wJYcSGrFor",
        "outputId": "9f01de6f-9b76-42cf-8632-edd1b750d0e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "language_model.model.layers.0.input_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.0.post_attention_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.0.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 2048, 256])\n",
            "language_model.model.layers.0.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.0.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.0.self_attn.o_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 256, 2048])\n",
            "language_model.model.layers.0.mlp.gate_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.0.mlp.up_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.0.mlp.down_proj.weight\n",
            "hf_tensor.shape=(2048, 16384)\n",
            "keras_variable.shape=TensorShape([16384, 2048])\n",
            "language_model.model.layers.1.input_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.1.post_attention_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.1.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 2048, 256])\n",
            "language_model.model.layers.1.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.1.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.1.self_attn.o_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 256, 2048])\n",
            "language_model.model.layers.1.mlp.gate_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.1.mlp.up_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.1.mlp.down_proj.weight\n",
            "hf_tensor.shape=(2048, 16384)\n",
            "keras_variable.shape=TensorShape([16384, 2048])\n",
            "language_model.model.layers.2.input_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.2.post_attention_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.2.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 2048, 256])\n",
            "language_model.model.layers.2.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.2.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.2.self_attn.o_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 256, 2048])\n",
            "language_model.model.layers.2.mlp.gate_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.2.mlp.up_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.2.mlp.down_proj.weight\n",
            "hf_tensor.shape=(2048, 16384)\n",
            "keras_variable.shape=TensorShape([16384, 2048])\n",
            "language_model.model.layers.3.input_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.3.post_attention_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.3.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 2048, 256])\n",
            "language_model.model.layers.3.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.3.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.3.self_attn.o_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 256, 2048])\n",
            "language_model.model.layers.3.mlp.gate_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.3.mlp.up_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.3.mlp.down_proj.weight\n",
            "hf_tensor.shape=(2048, 16384)\n",
            "keras_variable.shape=TensorShape([16384, 2048])\n",
            "language_model.model.layers.4.input_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.4.post_attention_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.4.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 2048, 256])\n",
            "language_model.model.layers.4.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.4.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.4.self_attn.o_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 256, 2048])\n",
            "language_model.model.layers.4.mlp.gate_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.4.mlp.up_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.4.mlp.down_proj.weight\n",
            "hf_tensor.shape=(2048, 16384)\n",
            "keras_variable.shape=TensorShape([16384, 2048])\n",
            "language_model.model.layers.5.input_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.5.post_attention_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.5.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 2048, 256])\n",
            "language_model.model.layers.5.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.5.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.5.self_attn.o_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 256, 2048])\n",
            "language_model.model.layers.5.mlp.gate_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.5.mlp.up_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.5.mlp.down_proj.weight\n",
            "hf_tensor.shape=(2048, 16384)\n",
            "keras_variable.shape=TensorShape([16384, 2048])\n",
            "language_model.model.layers.6.input_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.6.post_attention_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.6.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 2048, 256])\n",
            "language_model.model.layers.6.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.6.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.6.self_attn.o_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 256, 2048])\n",
            "language_model.model.layers.6.mlp.gate_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.6.mlp.up_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.6.mlp.down_proj.weight\n",
            "hf_tensor.shape=(2048, 16384)\n",
            "keras_variable.shape=TensorShape([16384, 2048])\n",
            "language_model.model.layers.7.input_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.7.post_attention_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.7.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 2048, 256])\n",
            "language_model.model.layers.7.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.7.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.7.self_attn.o_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 256, 2048])\n",
            "language_model.model.layers.7.mlp.gate_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.7.mlp.up_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.7.mlp.down_proj.weight\n",
            "hf_tensor.shape=(2048, 16384)\n",
            "keras_variable.shape=TensorShape([16384, 2048])\n",
            "language_model.model.layers.8.input_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.8.post_attention_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.8.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 2048, 256])\n",
            "language_model.model.layers.8.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.8.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.8.self_attn.o_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 256, 2048])\n",
            "language_model.model.layers.8.mlp.gate_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.8.mlp.up_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.8.mlp.down_proj.weight\n",
            "hf_tensor.shape=(2048, 16384)\n",
            "keras_variable.shape=TensorShape([16384, 2048])\n",
            "language_model.model.layers.9.input_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.9.post_attention_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.9.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 2048, 256])\n",
            "language_model.model.layers.9.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.9.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.9.self_attn.o_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 256, 2048])\n",
            "language_model.model.layers.9.mlp.gate_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.9.mlp.up_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.9.mlp.down_proj.weight\n",
            "hf_tensor.shape=(2048, 16384)\n",
            "keras_variable.shape=TensorShape([16384, 2048])\n",
            "language_model.model.layers.10.input_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.10.post_attention_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.10.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 2048, 256])\n",
            "language_model.model.layers.10.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.10.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.10.self_attn.o_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 256, 2048])\n",
            "language_model.model.layers.10.mlp.gate_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.10.mlp.up_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.10.mlp.down_proj.weight\n",
            "hf_tensor.shape=(2048, 16384)\n",
            "keras_variable.shape=TensorShape([16384, 2048])\n",
            "language_model.model.layers.11.input_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.11.post_attention_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.11.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 2048, 256])\n",
            "language_model.model.layers.11.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.11.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.11.self_attn.o_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 256, 2048])\n",
            "language_model.model.layers.11.mlp.gate_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.11.mlp.up_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.11.mlp.down_proj.weight\n",
            "hf_tensor.shape=(2048, 16384)\n",
            "keras_variable.shape=TensorShape([16384, 2048])\n",
            "language_model.model.layers.12.input_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.12.post_attention_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.12.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 2048, 256])\n",
            "language_model.model.layers.12.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.12.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.12.self_attn.o_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 256, 2048])\n",
            "language_model.model.layers.12.mlp.gate_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.12.mlp.up_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.12.mlp.down_proj.weight\n",
            "hf_tensor.shape=(2048, 16384)\n",
            "keras_variable.shape=TensorShape([16384, 2048])\n",
            "language_model.model.layers.13.input_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.13.post_attention_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.13.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 2048, 256])\n",
            "language_model.model.layers.13.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.13.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.13.self_attn.o_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 256, 2048])\n",
            "language_model.model.layers.13.mlp.gate_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.13.mlp.up_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.13.mlp.down_proj.weight\n",
            "hf_tensor.shape=(2048, 16384)\n",
            "keras_variable.shape=TensorShape([16384, 2048])\n",
            "language_model.model.layers.14.input_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.14.post_attention_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.14.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 2048, 256])\n",
            "language_model.model.layers.14.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.14.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.14.self_attn.o_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 256, 2048])\n",
            "language_model.model.layers.14.mlp.gate_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.14.mlp.up_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.14.mlp.down_proj.weight\n",
            "hf_tensor.shape=(2048, 16384)\n",
            "keras_variable.shape=TensorShape([16384, 2048])\n",
            "language_model.model.layers.15.input_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.15.post_attention_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.15.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 2048, 256])\n",
            "language_model.model.layers.15.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.15.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.15.self_attn.o_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 256, 2048])\n",
            "language_model.model.layers.15.mlp.gate_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.15.mlp.up_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.15.mlp.down_proj.weight\n",
            "hf_tensor.shape=(2048, 16384)\n",
            "keras_variable.shape=TensorShape([16384, 2048])\n",
            "language_model.model.layers.16.input_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.16.post_attention_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.16.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 2048, 256])\n",
            "language_model.model.layers.16.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.16.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.16.self_attn.o_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 256, 2048])\n",
            "language_model.model.layers.16.mlp.gate_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.16.mlp.up_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.16.mlp.down_proj.weight\n",
            "hf_tensor.shape=(2048, 16384)\n",
            "keras_variable.shape=TensorShape([16384, 2048])\n",
            "language_model.model.layers.17.input_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.17.post_attention_layernorm.weight\n",
            "hf_tensor.shape=(2048,)\n",
            "keras_variable.shape=TensorShape([2048])\n",
            "language_model.model.layers.17.self_attn.q_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 2048, 256])\n",
            "language_model.model.layers.17.self_attn.k_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.17.self_attn.v_proj.weight\n",
            "hf_tensor.shape=(256, 2048)\n",
            "keras_variable.shape=TensorShape([1, 2048, 256])\n",
            "language_model.model.layers.17.self_attn.o_proj.weight\n",
            "hf_tensor.shape=(2048, 2048)\n",
            "keras_variable.shape=TensorShape([8, 256, 2048])\n",
            "language_model.model.layers.17.mlp.gate_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.17.mlp.up_proj.weight\n",
            "hf_tensor.shape=(16384, 2048)\n",
            "keras_variable.shape=TensorShape([2048, 16384])\n",
            "language_model.model.layers.17.mlp.down_proj.weight\n",
            "hf_tensor.shape=(2048, 16384)\n",
            "keras_variable.shape=TensorShape([16384, 2048])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Norm"
      ],
      "metadata": {
        "id": "9xJHQUT870Un"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "port_weight(\n",
        "    keras_variable=keras_backbone.layer_norm.scale,\n",
        "    hf_weight_key=\"language_model.model.norm.weight\",\n",
        ")"
      ],
      "metadata": {
        "id": "Qk5H40G370Mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rest"
      ],
      "metadata": {
        "id": "SYaryVNaws_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "port_weight(\n",
        "    keras_variable=keras_backbone.token_embedding.embeddings,\n",
        "    hf_weight_key=\"language_model.model.embed_tokens.weight\",\n",
        "    hook_fn=lambda hf_tensor, keras_shape: hf_tensor[:keras_shape[0]]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzEeLWzZ2P9F",
        "outputId": "4f8a0c85-98a1-4529-c350-5874b0ba6579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "language_model.model.embed_tokens.weight\n",
            "hf_tensor.shape=(257216, 2048)\n",
            "keras_variable.shape=TensorShape([257152, 2048])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Congratulations\n",
        "\n",
        "Now that you have figured out all the weights match, go to Keras NLP and build your own `conver_model.py` script [here](https://github.com/keras-team/keras-nlp/tree/master/keras_nlp/src/utils/transformers)."
      ],
      "metadata": {
        "id": "pQ78Dt_loxhk"
      }
    }
  ]
}